{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a82c50a-1e66-43c2-8cd4-c2cf39e5edc4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pravinut/vnit/sem2/MLOPS/Assignments/Assignment2/data\n",
      "Updated sys.path: ['/opt/anaconda3/envs/mlopsproj/lib/python310.zip', '/opt/anaconda3/envs/mlopsproj/lib/python3.10', '/opt/anaconda3/envs/mlopsproj/lib/python3.10/lib-dynload', '', '/Users/pravinut/mlopsproj_py/lib/python3.10/site-packages', '/Users/pravinut/vnit/sem2/MLOPS/Assignments/Assignment2/aiml_orchestrators_assignment/src', '/Users/pravinut/vnit/sem2/MLOPS/Assignments/Assignment2/aiml_orchestrators_assignment/src']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the project root\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "DATA_PATH=os.path.abspath(os.path.join(os.getcwd(), \"../../data\"))\n",
    "MODEL_PATH=os.path.abspath(os.path.join(os.getcwd(), \"../models\"))\n",
    "print(DATA_PATH)\n",
    "# Add 'src/' to Python path\n",
    "sys.path.append(os.path.join(PROJECT_ROOT, \"src\"))\n",
    "\n",
    "# Verify the path\n",
    "print(\"Updated sys.path:\", sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f2721d4-3cbb-42ce-a474-0c82770b2113",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "def load_mnist_images(filename):\n",
    "    filepath = os.path.join(DATA_PATH, filename)\n",
    "    with open(filepath, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, 28, 28)\n",
    "    return images\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    filepath = os.path.join(DATA_PATH, filename)\n",
    "    with open(filepath, 'rb') as f:\n",
    "        magic, num = struct.unpack(\">II\", f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "# Load the dataset\n",
    "train_images = load_mnist_images(\"train-images.idx3-ubyte\")\n",
    "train_labels = load_mnist_labels(\"train-labels.idx1-ubyte\")\n",
    "test_images = load_mnist_images(\"t10k-images.idx3-ubyte\")\n",
    "test_labels = load_mnist_labels(\"t10k-labels.idx1-ubyte\")\n",
    "\n",
    "# Normalize images to range [0,1]\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "158494ba-7eb2-49e2-b43f-fea3e639ac33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9047 - loss: 0.3066 - val_accuracy: 0.9850 - val_loss: 0.0475\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.9870 - loss: 0.0446 - val_accuracy: 0.9870 - val_loss: 0.0405\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9900 - loss: 0.0319 - val_accuracy: 0.9857 - val_loss: 0.0431\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.9929 - loss: 0.0220 - val_accuracy: 0.9886 - val_loss: 0.0358\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.9942 - loss: 0.0162 - val_accuracy: 0.9893 - val_loss: 0.0382\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9863 - loss: 0.0507 \n",
      "Test Accuracy: 98.93%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Reshape the images for compatibility with TensorFlow\n",
    "train_images = train_images.reshape(-1, 28, 28, 1)\n",
    "test_images = test_images.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Build a simple CNN model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a546888-e264-4239-b3e3-b3a2c9b98546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: /Users/pravinut/vnit/sem2/MLOPS/Assignments/Assignment2/aiml_orchestrators_assignment/model/mnist_model.h5\n"
     ]
    }
   ],
   "source": [
    "model.save(os.path.join(MODEL_PATH, \"mnist_model.h5\"))\n",
    "print(\"Model saved at:\", os.path.join(MODEL_PATH, \"mnist_model.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7b3a4ab-da58-4a76-82cc-b5ef654d45a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/25 11:52:31 INFO mlflow.tracking.fluent: Experiment with name 'MNIST Experiment' does not exist. Creating a new experiment.\n",
      "/Users/pravinut/mlopsproj_py/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8754 - loss: 0.4095 - val_accuracy: 0.9841 - val_loss: 0.0498\n",
      "Epoch 2/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9828 - loss: 0.0531 - val_accuracy: 0.9867 - val_loss: 0.0393\n",
      "Epoch 3/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9888 - loss: 0.0372 - val_accuracy: 0.9903 - val_loss: 0.0288\n",
      "Epoch 4/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9917 - loss: 0.0273 - val_accuracy: 0.9881 - val_loss: 0.0374\n",
      "Epoch 5/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9930 - loss: 0.0228 - val_accuracy: 0.9906 - val_loss: 0.0287\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9878 - loss: 0.0381 \n",
      "Test Accuracy: 99.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025/02/25 11:53:29 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "\u001b[31m2025/02/25 11:53:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: /Users/pravinut/vnit/sem2/MLOPS/Assignments/Assignment2/model/mnist_model_adam_0.001.h5\n",
      "ðŸƒ View run judicious-colt-708 at: http://localhost:5000/#/experiments/688274167480846939/runs/c32dc237e255476faa74615e71353d7c\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/688274167480846939\n",
      "Epoch 1/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8304 - loss: 0.5605 - val_accuracy: 0.9809 - val_loss: 0.0618\n",
      "Epoch 2/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9791 - loss: 0.0695 - val_accuracy: 0.9836 - val_loss: 0.0523\n",
      "Epoch 3/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9848 - loss: 0.0505 - val_accuracy: 0.9864 - val_loss: 0.0415\n",
      "Epoch 4/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9889 - loss: 0.0357 - val_accuracy: 0.9892 - val_loss: 0.0331\n",
      "Epoch 5/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9907 - loss: 0.0292 - val_accuracy: 0.9867 - val_loss: 0.0372\n",
      "Epoch 6/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9918 - loss: 0.0256 - val_accuracy: 0.9891 - val_loss: 0.0314\n",
      "Epoch 7/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9937 - loss: 0.0203 - val_accuracy: 0.9905 - val_loss: 0.0278\n",
      "Epoch 8/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9951 - loss: 0.0161 - val_accuracy: 0.9901 - val_loss: 0.0295\n",
      "Epoch 9/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9957 - loss: 0.0140 - val_accuracy: 0.9898 - val_loss: 0.0296\n",
      "Epoch 10/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9972 - loss: 0.0104 - val_accuracy: 0.9888 - val_loss: 0.0319\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.0368 \n",
      "Test Accuracy: 98.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025/02/25 11:55:29 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "\u001b[31m2025/02/25 11:55:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: /Users/pravinut/vnit/sem2/MLOPS/Assignments/Assignment2/model/mnist_model_adam_0.0005.h5\n",
      "ðŸƒ View run bemused-duck-536 at: http://localhost:5000/#/experiments/688274167480846939/runs/25eb0ad3eaad4a29b0041bff580facde\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/688274167480846939\n",
      "Epoch 1/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.5652 - loss: 1.5021 - val_accuracy: 0.8922 - val_loss: 0.3435\n",
      "Epoch 2/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9172 - loss: 0.2732 - val_accuracy: 0.9471 - val_loss: 0.1755\n",
      "Epoch 3/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9459 - loss: 0.1817 - val_accuracy: 0.9517 - val_loss: 0.1513\n",
      "Epoch 4/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9597 - loss: 0.1335 - val_accuracy: 0.9660 - val_loss: 0.1091\n",
      "Epoch 5/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9670 - loss: 0.1072 - val_accuracy: 0.9720 - val_loss: 0.0916\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9679 - loss: 0.1051 \n",
      "Test Accuracy: 97.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025/02/25 11:56:31 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "\u001b[31m2025/02/25 11:56:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: /Users/pravinut/vnit/sem2/MLOPS/Assignments/Assignment2/model/mnist_model_sgd_0.01.h5\n",
      "ðŸƒ View run vaunted-koi-180 at: http://localhost:5000/#/experiments/688274167480846939/runs/ac12776c22e040a1b352fe27e16d5549\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/688274167480846939\n",
      "Epoch 1/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8782 - loss: 0.3976 - val_accuracy: 0.9851 - val_loss: 0.0490\n",
      "Epoch 2/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9844 - loss: 0.0523 - val_accuracy: 0.9892 - val_loss: 0.0315\n",
      "Epoch 3/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9897 - loss: 0.0342 - val_accuracy: 0.9894 - val_loss: 0.0322\n",
      "Epoch 4/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9926 - loss: 0.0247 - val_accuracy: 0.9897 - val_loss: 0.0287\n",
      "Epoch 5/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9940 - loss: 0.0201 - val_accuracy: 0.9896 - val_loss: 0.0305\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9862 - loss: 0.0387 \n",
      "Test Accuracy: 98.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025/02/25 11:57:35 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "\u001b[31m2025/02/25 11:57:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: /Users/pravinut/vnit/sem2/MLOPS/Assignments/Assignment2/model/mnist_model_rmsprop_0.001.h5\n",
      "ðŸƒ View run youthful-rook-298 at: http://localhost:5000/#/experiments/688274167480846939/runs/f543ff7b860649c0a78b61b5d05df2d2\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/688274167480846939\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import struct\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Set up paths\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "DATA_PATH = os.path.abspath(os.path.join(os.getcwd(), \"../../data\"))\n",
    "MODEL_PATH = os.path.abspath(os.path.join(os.getcwd(), \"../../model\"))\n",
    "\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "\n",
    "# Load MNIST dataset\n",
    "def load_mnist_images(filename):\n",
    "    filepath = os.path.join(DATA_PATH, filename)\n",
    "    with open(filepath, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, 28, 28)\n",
    "    return images\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    filepath = os.path.join(DATA_PATH, filename)\n",
    "    with open(filepath, 'rb') as f:\n",
    "        magic, num = struct.unpack(\">II\", f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "train_images = load_mnist_images(\"train-images.idx3-ubyte\")\n",
    "train_labels = load_mnist_labels(\"train-labels.idx1-ubyte\")\n",
    "test_images = load_mnist_images(\"t10k-images.idx3-ubyte\")\n",
    "test_labels = load_mnist_labels(\"t10k-labels.idx1-ubyte\")\n",
    "\n",
    "# Normalize data\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Reshape for TensorFlow\n",
    "train_images = train_images.reshape(-1, 28, 28, 1)\n",
    "test_images = test_images.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# MLflow Tracking URI (optional: use remote server)\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")  # Change if using a remote MLflow server\n",
    "mlflow.set_experiment(\"MNIST Experiment\")\n",
    "\n",
    "# Function to train model with different hyperparameters\n",
    "def train_and_log_model(optimizer='adam', learning_rate=0.001, epochs=5, batch_size=64):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param(\"optimizer\", optimizer)\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "\n",
    "        # Define model\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "            keras.layers.MaxPooling2D((2, 2)),\n",
    "            keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            keras.layers.MaxPooling2D((2, 2)),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(64, activation='relu'),\n",
    "            keras.layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        # Compile model with different optimizers\n",
    "        if optimizer == \"adam\":\n",
    "            opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        elif optimizer == \"sgd\":\n",
    "            opt = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "        elif optimizer == \"rmsprop\":\n",
    "            opt = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported optimizer!\")\n",
    "\n",
    "        model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train model\n",
    "        history = model.fit(train_images, train_labels, \n",
    "                            epochs=epochs, \n",
    "                            batch_size=batch_size,\n",
    "                            validation_data=(test_images, test_labels))\n",
    "\n",
    "        # Evaluate model\n",
    "        test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "        print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"test_accuracy\", test_acc)\n",
    "        mlflow.log_metric(\"test_loss\", test_loss)\n",
    "\n",
    "        # Save model\n",
    "        model_path = os.path.join(MODEL_PATH, f\"mnist_model_{optimizer}_{learning_rate}.h5\")\n",
    "        model.save(model_path)\n",
    "        mlflow.tensorflow.log_model(model, artifact_path=\"model\")\n",
    "\n",
    "        print(\"Model saved at:\", model_path)\n",
    "\n",
    "# Run different experiments\n",
    "train_and_log_model(optimizer=\"adam\", learning_rate=0.001, epochs=5, batch_size=64)\n",
    "train_and_log_model(optimizer=\"adam\", learning_rate=0.0005, epochs=10, batch_size=64)\n",
    "train_and_log_model(optimizer=\"sgd\", learning_rate=0.01, epochs=5, batch_size=64)\n",
    "train_and_log_model(optimizer=\"rmsprop\", learning_rate=0.001, epochs=5, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a838b6bd-1c58-4ad4-970b-7d1cfcde290f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/25 12:02:48 INFO mlflow.tracking.fluent: Experiment with name 'MNIST Experiment PyTorch' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.040879782289266586\n",
      "Epoch 2, Loss: 0.05770434811711311\n",
      "Epoch 3, Loss: 0.009696338325738907\n",
      "Epoch 4, Loss: 0.0024149278178811073\n",
      "Epoch 5, Loss: 0.02982061356306076\n",
      "Test Accuracy: 0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/02/25 12:05:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: /Users/pravinut/vnit/sem2/MLOPS/Assignments/Assignment2/model/mnist_model_pytorch_adam_0.001.pth\n",
      "ðŸƒ View run invincible-goat-264 at: http://localhost:5000/#/experiments/917714700599549108/runs/4173e2e68e634767be47377a7a0ee8a9\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/917714700599549108\n",
      "Epoch 1, Loss: 0.056410931050777435\n",
      "Epoch 2, Loss: 0.011537907645106316\n",
      "Epoch 3, Loss: 0.012936309911310673\n",
      "Epoch 4, Loss: 0.10841992497444153\n",
      "Epoch 5, Loss: 0.005705532617866993\n",
      "Epoch 6, Loss: 0.0024919300340116024\n",
      "Epoch 7, Loss: 0.06047149747610092\n",
      "Epoch 8, Loss: 0.014097253791987896\n",
      "Epoch 9, Loss: 0.00027870299527421594\n",
      "Epoch 10, Loss: 0.0018808655440807343\n",
      "Test Accuracy: 0.9902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/02/25 12:09:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: /Users/pravinut/vnit/sem2/MLOPS/Assignments/Assignment2/model/mnist_model_pytorch_adam_0.0005.pth\n",
      "ðŸƒ View run flawless-loon-704 at: http://localhost:5000/#/experiments/917714700599549108/runs/a6cca298bd1f498c81e2540b4b4a9041\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/917714700599549108\n",
      "Epoch 1, Loss: 0.4543495178222656\n",
      "Epoch 2, Loss: 0.3479456305503845\n",
      "Epoch 3, Loss: 0.03886400908231735\n",
      "Epoch 4, Loss: 0.14029084146022797\n",
      "Epoch 5, Loss: 0.08178677409887314\n",
      "Test Accuracy: 0.9685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/02/25 12:12:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: /Users/pravinut/vnit/sem2/MLOPS/Assignments/Assignment2/model/mnist_model_pytorch_sgd_0.01.pth\n",
      "ðŸƒ View run auspicious-fawn-444 at: http://localhost:5000/#/experiments/917714700599549108/runs/de5928e6c71d455e9548c3d4a4b46864\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/917714700599549108\n",
      "Epoch 1, Loss: 0.12048418819904327\n",
      "Epoch 2, Loss: 0.1756865233182907\n",
      "Epoch 3, Loss: 0.0034798074048012495\n",
      "Epoch 4, Loss: 0.06390583515167236\n",
      "Epoch 5, Loss: 0.017232922837138176\n",
      "Test Accuracy: 0.9881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/02/25 12:14:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: /Users/pravinut/vnit/sem2/MLOPS/Assignments/Assignment2/model/mnist_model_pytorch_rmsprop_0.001.pth\n",
      "ðŸƒ View run intelligent-duck-421 at: http://localhost:5000/#/experiments/917714700599549108/runs/b117ff4027614fb89fb804d19c491ebf\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/917714700599549108\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set paths\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "DATA_PATH = os.path.abspath(os.path.join(os.getcwd(), \"../../data\"))\n",
    "MODEL_PATH = os.path.abspath(os.path.join(os.getcwd(), \"../models\"))\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "\n",
    "# Load MNIST dataset\n",
    "def load_mnist_images(filename):\n",
    "    filepath = os.path.join(DATA_PATH, filename)\n",
    "    with open(filepath, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, 28, 28)\n",
    "    return images\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    filepath = os.path.join(DATA_PATH, filename)\n",
    "    with open(filepath, 'rb') as f:\n",
    "        magic, num = struct.unpack(\">II\", f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "train_images = load_mnist_images(\"train-images.idx3-ubyte\")\n",
    "train_labels = load_mnist_labels(\"train-labels.idx1-ubyte\")\n",
    "test_images = load_mnist_images(\"t10k-images.idx3-ubyte\")\n",
    "test_labels = load_mnist_labels(\"t10k-labels.idx1-ubyte\")\n",
    "\n",
    "# Normalize data\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_images_tensor = torch.tensor(train_images, dtype=torch.float32).unsqueeze(1)  # Add channel dim\n",
    "train_labels_tensor = torch.tensor(train_labels, dtype=torch.long)\n",
    "test_images_tensor = torch.tensor(test_images, dtype=torch.float32).unsqueeze(1)\n",
    "test_labels_tensor = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "test_dataset = TensorDataset(test_images_tensor, test_labels_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define CNN Model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# MLflow setup\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")  # Change for remote MLflow server\n",
    "mlflow.set_experiment(\"MNIST Experiment PyTorch\")\n",
    "\n",
    "# Function to train model\n",
    "def train_and_log_model(optimizer_type='adam', learning_rate=0.001, epochs=5, batch_size=64):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param(\"framework\", \"pytorch\")\n",
    "        mlflow.log_param(\"optimizer\", optimizer_type)\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "\n",
    "        model = CNN()\n",
    "        \n",
    "        if optimizer_type == \"adam\":\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        elif optimizer_type == \"sgd\":\n",
    "            optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "        elif optimizer_type == \"rmsprop\":\n",
    "            optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported optimizer!\")\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Training Loop\n",
    "        for epoch in range(epochs):\n",
    "            for images, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "        # Evaluate Model\n",
    "        correct, total = 0, 0\n",
    "        y_preds, y_trues = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                y_preds.extend(predicted.numpy())\n",
    "                y_trues.extend(labels.numpy())\n",
    "\n",
    "        accuracy = accuracy_score(y_trues, y_preds)\n",
    "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Log results\n",
    "        mlflow.log_metric(\"test_accuracy\", accuracy)\n",
    "        mlflow.pytorch.log_model(model, \"model\")\n",
    "\n",
    "        # Save model\n",
    "        model_path = os.path.join(MODEL_PATH, f\"mnist_model_pytorch_{optimizer_type}_{learning_rate}.pth\")\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(\"Model saved at:\", model_path)\n",
    "\n",
    "# Run different experiments\n",
    "train_and_log_model(optimizer_type=\"adam\", learning_rate=0.001, epochs=5, batch_size=64)\n",
    "train_and_log_model(optimizer_type=\"adam\", learning_rate=0.0005, epochs=10, batch_size=64)\n",
    "train_and_log_model(optimizer_type=\"sgd\", learning_rate=0.01, epochs=5, batch_size=64)\n",
    "train_and_log_model(optimizer_type=\"rmsprop\", learning_rate=0.001, epochs=5, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0203794b-14e2-462c-8d91-edfb021c56cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.03241514414548874\n",
      "Epoch 2, Loss: 0.014767859131097794\n",
      "Epoch 3, Loss: 0.030488135293126106\n",
      "Epoch 4, Loss: 0.0010689987102523446\n",
      "Epoch 5, Loss: 0.0004080650396645069\n",
      "Test Accuracy: 0.9882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/02/25 14:57:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: /Users/pravinut/vnit/sem2/MLOPS/Assignments/Assignment2/aiml_orchestrators_assignment/models/mnist_model_pytorch_adam_0.001.pth\n",
      "ðŸƒ View run rare-hound-94 at: http://localhost:5000/#/experiments/917714700599549108/runs/e442d624303a471385d90aaf59d76dcd\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/917714700599549108\n",
      "Epoch 1, Loss: 0.056003641337156296\n",
      "Epoch 2, Loss: 0.02509920299053192\n",
      "Epoch 3, Loss: 0.0037948626559227705\n",
      "Epoch 4, Loss: 0.020609175786376\n",
      "Epoch 5, Loss: 0.0011451035970821977\n",
      "Epoch 6, Loss: 0.009010781534016132\n",
      "Epoch 7, Loss: 0.10222824662923813\n",
      "Epoch 8, Loss: 0.002100937068462372\n",
      "Epoch 9, Loss: 0.01915203034877777\n",
      "Epoch 10, Loss: 0.0058694081380963326\n",
      "Test Accuracy: 0.9886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/02/25 15:01:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: /Users/pravinut/vnit/sem2/MLOPS/Assignments/Assignment2/aiml_orchestrators_assignment/models/mnist_model_pytorch_adam_0.0005.pth\n",
      "ðŸƒ View run thundering-perch-198 at: http://localhost:5000/#/experiments/917714700599549108/runs/dc9d8b1f65d54f6f82f89e7a16b637ca\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/917714700599549108\n",
      "Epoch 1, Loss: 0.3711227476596832\n",
      "Epoch 2, Loss: 0.2263508439064026\n",
      "Epoch 3, Loss: 0.29550421237945557\n",
      "Epoch 4, Loss: 0.2700895369052887\n",
      "Epoch 5, Loss: 0.22489100694656372\n",
      "Test Accuracy: 0.9669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/02/25 15:02:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: /Users/pravinut/vnit/sem2/MLOPS/Assignments/Assignment2/aiml_orchestrators_assignment/models/mnist_model_pytorch_sgd_0.01.pth\n",
      "ðŸƒ View run rogue-cod-233 at: http://localhost:5000/#/experiments/917714700599549108/runs/ce88e10e2f234ea79e7d4e22f3d63b7b\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/917714700599549108\n",
      "Epoch 1, Loss: 0.046352457255125046\n",
      "Epoch 2, Loss: 0.016106197610497475\n",
      "Epoch 3, Loss: 0.013561534695327282\n",
      "Epoch 4, Loss: 0.006273791193962097\n",
      "Epoch 5, Loss: 0.0036959885619580746\n",
      "Test Accuracy: 0.9890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/02/25 15:04:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: /Users/pravinut/vnit/sem2/MLOPS/Assignments/Assignment2/aiml_orchestrators_assignment/models/mnist_model_pytorch_rmsprop_0.001.pth\n",
      "ðŸƒ View run hilarious-eel-781 at: http://localhost:5000/#/experiments/917714700599549108/runs/4faf36d8ab8a48d1967075966a7bb631\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/917714700599549108\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import struct\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set paths\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "DATA_PATH = os.path.abspath(os.path.join(os.getcwd(), \"../../data\"))\n",
    "MODEL_PATH = os.path.abspath(os.path.join(os.getcwd(), \"../models\"))\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "\n",
    "# Load MNIST dataset\n",
    "def load_mnist_images(filename):\n",
    "    filepath = os.path.join(DATA_PATH, filename)\n",
    "    with open(filepath, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, 1, 28, 28)  # Ensure correct shape\n",
    "    return images\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    filepath = os.path.join(DATA_PATH, filename)\n",
    "    with open(filepath, 'rb') as f:\n",
    "        magic, num = struct.unpack(\">II\", f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "train_images = load_mnist_images(\"train-images.idx3-ubyte\")\n",
    "train_labels = load_mnist_labels(\"train-labels.idx1-ubyte\")\n",
    "test_images = load_mnist_images(\"t10k-images.idx3-ubyte\")\n",
    "test_labels = load_mnist_labels(\"t10k-labels.idx1-ubyte\")\n",
    "\n",
    "# Normalize data\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_images_tensor = torch.tensor(train_images, dtype=torch.float32)\n",
    "train_labels_tensor = torch.tensor(train_labels, dtype=torch.long)\n",
    "test_images_tensor = torch.tensor(test_images, dtype=torch.float32)\n",
    "test_labels_tensor = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "test_dataset = TensorDataset(test_images_tensor, test_labels_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define CNN Model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# MLflow setup\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"MNIST Experiment PyTorch\")\n",
    "\n",
    "# Function to train model\n",
    "def train_and_log_model(optimizer_type='adam', learning_rate=0.001, epochs=5, batch_size=64):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param(\"framework\", \"pytorch\")\n",
    "        mlflow.log_param(\"optimizer\", optimizer_type)\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "\n",
    "        model = CNN()\n",
    "        \n",
    "        if optimizer_type == \"adam\":\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        elif optimizer_type == \"sgd\":\n",
    "            optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "        elif optimizer_type == \"rmsprop\":\n",
    "            optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported optimizer!\")\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Training Loop\n",
    "        for epoch in range(epochs):\n",
    "            for images, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "        # Evaluate Model\n",
    "        correct, total = 0, 0\n",
    "        y_preds, y_trues = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                y_preds.extend(predicted.numpy())\n",
    "                y_trues.extend(labels.numpy())\n",
    "\n",
    "        accuracy = accuracy_score(y_trues, y_preds)\n",
    "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Log results\n",
    "        mlflow.log_metric(\"test_accuracy\", accuracy)\n",
    "        mlflow.pytorch.log_model(model, \"model\")\n",
    "\n",
    "        # Save model\n",
    "        model_path = os.path.join(MODEL_PATH, f\"mnist_model_pytorch_{optimizer_type}_{learning_rate}.pth\")\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(\"Model saved at:\", model_path)\n",
    "\n",
    "# Run different experiments\n",
    "train_and_log_model(optimizer_type=\"adam\", learning_rate=0.001, epochs=5, batch_size=64)\n",
    "train_and_log_model(optimizer_type=\"adam\", learning_rate=0.0005, epochs=10, batch_size=64)\n",
    "train_and_log_model(optimizer_type=\"sgd\", learning_rate=0.01, epochs=5, batch_size=64)\n",
    "train_and_log_model(optimizer_type=\"rmsprop\", learning_rate=0.001, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee3cb32-4940-41ea-9454-eb7fec1c23e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlopsproj_py)",
   "language": "python",
   "name": "mlopsproj_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
